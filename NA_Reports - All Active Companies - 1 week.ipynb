{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: Rolling 1 week window of all active client NA data. \n",
    "Pull date from curated_task_fields and merge that with the product data, to find the products that are receving NA data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Get the previous date\n",
    "from datetime import date, timedelta, datetime\n",
    "\n",
    "#Interacting with Postgres SQL\n",
    "import psycopg2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "#importing database\n",
    "from database_config import postgres as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establishing Connection to Postgres via psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the connection to the PostgreSQL -feeddate\n",
    "conn = psycopg2.connect(**cfg)\n",
    "\n",
    "#this works with the last days of the month as well. \n",
    "todays_date = str(datetime.today())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_client_query = (\"\"\"\n",
    "SELECT \n",
    "    id,\n",
    "    name\n",
    "FROM \"public\".\"customers\" \n",
    "WHERE active = 't';\n",
    "\"\"\")\n",
    "\n",
    "active_client = pd.read_sql(active_client_query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the clients that have NA values\n",
    "rel_client = next(iter(active_client.to_dict().values()))\n",
    "\n",
    "#Statement is setup to only pull the unique list of clients that have Null values in the past week.\n",
    "rel_query = (\"\"\"\n",
    "    SELECT \n",
    "        DISTINCT ct.customer_id\n",
    "    FROM \"curation_tasks\" AS ct\n",
    "    WHERE started_at >= CURRENT_TIMESTAMP - INTERVAL '1 week'\n",
    "    AND (ct.resolution IS NULL OR ct.resolution = 'misclassified') \n",
    "    LIMIT 100\"\"\")\n",
    "\n",
    "rel_client = pd.read_sql(rel_query,conn)\n",
    "\n",
    "#Using this list to restrict query.\n",
    "rel_client_weekly = list(rel_client['customer_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching through the active clients to get their ID's\n",
    "active_client = active_client[active_client['id'].isin(rel_client_weekly)]\n",
    "\n",
    "active_client.set_index('id',drop=True,inplace=True)\n",
    "\n",
    "important_customers = next(iter(active_client.to_dict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NA_report(customer_id,timeframe,to_csv=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ------------------------------------------------\n",
    "    customer_id: ensure it matches the SQL database\n",
    "    \n",
    "    timeframe: ensure this is a string. examples('1 month','5 weeks','1 year')\n",
    "    \n",
    "    Details:\n",
    "    ######################################################################################\n",
    "    Sub query:\n",
    "    This query pulls in all curated product tasks by ID.It converts the data NA values to a 1, so we can sum them.\n",
    "    We also, count the unique ids to find the total number of tasks completed.\n",
    "\n",
    "    Main query:\n",
    "    This suquery is joined on to each individual curation task ID.\n",
    "    This pulls in all active client curation tass\n",
    "    In order to aggregate the date faster by day the date has been truncated.\n",
    "    The resolution is used to pull only null or misclassified product curations. -- Reason for this is to avoid bulk curation\n",
    "    ######################################################################################\n",
    "    \"\"\"\n",
    "\n",
    "    company_na_reports = (  \n",
    "    '''SELECT \n",
    "        ct.\"id\" AS curation_task_id, \n",
    "        ct.customer_id, \n",
    "        ct.resolution, \n",
    "        --- truncated the timestamp from the date for aggregation.\n",
    "        date_trunc('day',ct.started_at) as \"started_at\",\n",
    "        cpf.product_id,\n",
    "        cpf.\"name\" AS attribute_name, \n",
    "        cpf.\"Total_NAs\", \n",
    "        cpf.curation_tasks_count\n",
    "    FROM \"curation_tasks\" AS ct\n",
    "\n",
    "    INNER JOIN \n",
    "        (SELECT \n",
    "            cpf.curation_task_id,\n",
    "            cpf.customer_id,\n",
    "            cpf.product_id,\n",
    "            cpf.name, \n",
    "            SUM(CASE WHEN cpf.value = 'n/a' THEN 1 ELSE 0 END) as \"Total_NAs\",\n",
    "            COUNT(cpf.id) AS curation_tasks_count\n",
    "        FROM \"public\".\"curated_product_fields\"  as cpf\n",
    "        WHERE customer_id = {}\n",
    "        GROUP BY\n",
    "            cpf.curation_task_id,    \n",
    "            cpf.customer_id,\n",
    "            cpf.product_id,\n",
    "            cpf.name\n",
    "        ) AS cpf\n",
    "    ON ct.id = cpf.curation_task_id\n",
    "\n",
    "    WHERE started_at >= CURRENT_TIMESTAMP - INTERVAL {!r}\n",
    "    --- specific resolution that are not taken care of my rules or bulk\n",
    "    AND (ct.resolution IS NULL OR ct.resolution = 'misclassified') \n",
    "    AND ct.customer_id = {}\n",
    "    ORDER BY started_at;\n",
    "    ''')\n",
    "\n",
    "    #creating a blank data set to append to. \n",
    "    master_data = pd.DataFrame()\n",
    "\n",
    "    print(\"process has begun\")\n",
    "    for cust in customer_id:\n",
    "        #Returning the data in pandas to export it as a CSV.\n",
    "        data = pd.read_sql(company_na_reports.format(cust,timeframe,cust),conn)\n",
    "\n",
    "        #if the there is data, convert the date to a date element and append the customer name\n",
    "        if data.shape[0] != 0:\n",
    "            data['started_at'] = data['started_at'].dt.date\n",
    "            data['customer_name']= important_customers[cust]\n",
    "            print(cust, 'query and data clean completed')\n",
    "        else:\n",
    "            print('No data available in your time frame for Cust_id ',cust)\n",
    "            pass\n",
    "        master_data = master_data.append(data,sort=False)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    if to_csv:\n",
    "        master_data.to_csv('C:/Users/groupby/Documents/Github/NA_Report/data/customer_'+str(customer_id)+'_'+timeframe+'_NA_report.csv',index=False)\n",
    "    return master_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-391a591713d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Searching Null values and searching for only those results to be pulled from the product table.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munique_prod_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaster_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'product_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Py to SQL formatting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0muni_prod_sql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_prod_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"]\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'master_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Searching Null values and searching for only those results to be pulled from the product table.\n",
    "unique_prod_list = list(master_data['product_id'].unique())\n",
    "\n",
    "#Py to SQL formatting.\n",
    "uni_prod_sql = str(unique_prod_list).replace(\"[\",'').replace(\"]\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_customers = list(important_customers.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying N/A Product data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_product= ('''SELECT\n",
    "    p.customer_id,\n",
    "    pbb.bucket_name,\n",
    "    p.product_id,\n",
    "    p.product_name,\n",
    "    p.active,\n",
    "    p.external_id,\n",
    "    p.image_url,\n",
    "    sba.family_friendly\n",
    "FROM (SELECT\n",
    "            p.id as product_id,\n",
    "            p.active,\n",
    "            p.customer_id,\n",
    "            p.name as product_name,\n",
    "            p.external_id,\n",
    "            p.image_url\n",
    "        FROM products as p\n",
    "        WHERE p.customer_id  = {}\n",
    "        AND p.active = 't'\n",
    "        AND p.id in ({})) AS p\n",
    "INNER JOIN (SELECT\n",
    "            pb.product_id\n",
    "            ,pb.bucket_id\n",
    "            ,buc.bucket_name\n",
    "            FROM products_buckets AS pb\n",
    "            INNER JOIN (SELECT\n",
    "                            id AS bucket_id\n",
    "                            ,name AS bucket_name\n",
    "                        FROM buckets) AS buc\n",
    "            ON buc.bucket_id = pb.bucket_id) AS pbb\n",
    "ON p.product_id = pbb.product_id\n",
    "INNER JOIN (SELECT \n",
    "                sb.bucket_id, \n",
    "                sxa.attribute_id, \n",
    "                family_friendly \n",
    "                FROM strategy_buckets as sb\n",
    "                    INNER JOIN (SELECT \n",
    "                                    id, \n",
    "                                    strategy_bucket_id, \n",
    "                                    attribute_id,\n",
    "                                    family_friendly \n",
    "                                    FROM strategy_buckets_attributes) as sxa\n",
    "                    ON sb.id = sxa.strategy_bucket_id) as sba\n",
    "ON pbb.bucket_id = sba.bucket_id\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reseting the data\n",
    "master_data_prod = pd.DataFrame(columns=['customer_id','bucket_id','bucket_name','product_id','product_name','active','external_id','image_url','attribute_id','family_friendly'])\n",
    "master_data_prod.to_csv('C:/Users/groupby/Documents/Github/NA_Report/data/Weekly_products.csv',mode='w',index=False,header=True)\n",
    "counter = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_products(cust_id):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -------------\n",
    "    cust_id: 13 or [45,77,75]\n",
    "    {expected input is an int or list of ints of customer ID's}\n",
    "    --------------\n",
    "    \n",
    "    Description:\n",
    "    Finds all active prodcuts and appends them to a document.\n",
    "    \"\"\"\n",
    "    for data_prod in pd.read_sql(query_product.format(cust_id,uni_prod_sql),conn,chunksize=100000):\n",
    "        if data_prod.shape[0] == 0:\n",
    "            print('No data_prod available in your time frame for Cust_ID ',cust)\n",
    "        data_prod.to_csv('C:/Users/groupby/Documents/Python Scripts/NA_Reports/data/Weekly_products.csv',mode='a',index=False,header=False)\n",
    "    print('Cust_id ',cust_id, 'Product query and data clean completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel in relevant_customers:\n",
    "    try:\n",
    "        client_products(rel)\n",
    "        counter += 1\n",
    "        print(str(counter)+' completed of '+str(len(relevant_customers)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query setup to collect any data that is likely to be a family item. \n",
    "def family_friendly_data(to_csv=False,file_save_to='./data/'):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    to_csv: default False\n",
    "    True or False\n",
    "    \n",
    "    file_save_to: 'Desktop'\n",
    "    Input str of file path.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ff_query =(\n",
    "    \"\"\" SELECT DISTINCT\n",
    "        sba.attribute_id,\n",
    "        a.snake_case_name, \n",
    "        family_friendly\n",
    "    FROM strategy_buckets_attributes AS sba\n",
    "    INNER JOIN (SELECT id as attribute_id, \n",
    "                        snake_case_name \n",
    "                FROM attributes) AS a\n",
    "    ON sba.attribute_id = a.attribute_id\n",
    "    \"\"\")\n",
    "\n",
    "    ff =pd.read_sql(ff_query,conn)\n",
    "\n",
    "    ff.sort_values(by='attribute_id')\n",
    "    if to_csv:\n",
    "        ff.to_csv(file_save_to+'family_friendly.csv')\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a log ensure it runs daily.\n",
    "if master_data.shape[0] > 0:\n",
    "    with open('G:/My Drive/Projects/NA_Reports/Weekly_NA_Report/Weekly_NA_Report_log.txt','r+',encoding='utf-8') as f:\n",
    "        previous_contents =f.read()\n",
    "        #appends data to the top of the document for quick glance.\n",
    "        f.seek(0,0)\n",
    "        f.write(todays_date+' update has been confirmed.\\n')\n",
    "        f.write(previous_contents)\n",
    "else:\n",
    "    with open('G:/My Drive/Projects/NA_Reports/Weekly_NA_Report/Weekly_NA_Report_log.txt','r+',encoding='utf-8') as f:\n",
    "        previous_contents =f.read()\n",
    "        f.seek(0,0)\n",
    "        f.write(todays_date+' an error has occured and no data has been updated.\\n')\n",
    "        f.write(previous_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
